{"cells":[{"cell_type":"markdown","metadata":{"id":"wkYjlPX8FBGy"},"source":["# DeepSDF"]},{"cell_type":"markdown","metadata":{"id":"6cJofBMccufA"},"source":["<font color='red'>NOTE : </font> <font color='green'>Lets use the notebooks only for testing and debugging purposes. We need a .py file that we can use in the notebook. </font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qosud1sdepVS"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17907,"status":"ok","timestamp":1701827520049,"user":{"displayName":"Jemuel Premkumar","userId":"15271811269029043422"},"user_tz":300},"id":"geLvhL3qeK59","outputId":"480b4342-af93-4206-b2b2-eb125fb5269b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","['data', 'requirements.txt', 'utils', 'params.json', 'reconstruction.py', 'hello_testing.py', '__pycache__', 'PCN.ipynb', 'Reconstruct.ipynb', 'Grasp Generation.ipynb', 'dataset.py', '.ipynb_checkpoints', 'config_files', 'model', 'results', 'scripts', 'obj_paths.pkl', 'Dataset.ipynb', 'eval']\n"]}],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# TODO: Fill this according to your drive loc\n","# DAVID: GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '/DeepSDF/'\n","# STANLEY: GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'ROB 498 3D Robot Perception/3D-RP-Project/DeepSDF/'\n","# DEEPAK:\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'ROB 498 3D Robot Perception/3D-RP-Project/DeepSDF/' # Edit and replace | Don't delete my directory lol\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'DeepSDF/'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"markdown","metadata":{"id":"v8l3_SWmh8Uo"},"source":["If you did everything right, you should see something like this:\n","```\n","['DeepSDF.ipynb', 'data', 'models', 'requirements.txt', 'utils', 'params.json', 'Reconstruct.ipynb', 'Dataset.ipynb', 'hello_testing.py', 'model.py', '__pycache__']\n","```"]},{"cell_type":"markdown","metadata":{"id":"fg2vStctuE0M"},"source":["<font color='red'>NOTE:</font> You don't have to clone the shared drive.\n","1. Create a shortcut of the shared folder (DeepSDF) and place in your drive.\n","2. Then change the directory on the notebook according to your gdrive."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":696,"status":"ok","timestamp":1701827520736,"user":{"displayName":"Jemuel Premkumar","userId":"15271811269029043422"},"user_tz":300},"id":"w8CikRGDgY_B","outputId":"1fc00551-4fae-48fd-e807-393f2470dcc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Working!\n","model.py last edited on Sun Nov  5 17:43:40 2023\n"]}],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()\n","\n","from hello_testing import hello\n","hello()\n","\n","model_path = os.path.join(GOOGLE_DRIVE_PATH, 'model/model.py')\n","model_edit_time = time.ctime(os.path.getmtime(model_path))\n","print('model.py last edited on %s' % model_edit_time)"]},{"cell_type":"markdown","metadata":{"id":"tbSZErrxlLZ9"},"source":["Navigate to :\n","\n","```drive > .... > 3D-RP-Project > model.py```\n","\n","Double-click on the file to open it on the side."]},{"cell_type":"markdown","metadata":{"id":"m5DOKwbuT015"},"source":["## model.py"]},{"cell_type":"markdown","metadata":{"id":"o1FJfgm1T4ch"},"source":["## train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5Y_wHw7YXZJ"},"outputs":[],"source":["import torch\n","import model.model_sdf as sdf_model\n","import torch.optim as optim\n","import data.dataset_sdf as dataset\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","import results.runs_sdf as runs\n","from utils.utils_deepsdf import SDFLoss_multishape\n","import os\n","from datetime import datetime\n","import numpy as np\n","import time\n","from utils import utils_deepsdf\n","import results\n","# from torch.utils.tensorboard import SummaryWriter\n","import yaml\n","import config_files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1701827528822,"user":{"displayName":"Jemuel Premkumar","userId":"15271811269029043422"},"user_tz":300},"id":"AT9Ets7waggv","outputId":"5dac8213-5b57-4497-fe86-cb780fb02d95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cpu\n"]}],"source":["# Select device. The 'mps' device (macOS M1 architecture) is not supported as it cannot currently handle weith normalisation.\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(f'Device: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":900},"executionInfo":{"elapsed":10328502,"status":"error","timestamp":1701588381420,"user":{"displayName":"Jemuel Stanley","userId":"07835643054669309596"},"user_tz":300},"id":"TfnDqKAcasa5","outputId":"fb725d6d-94df-4562-beef-2715f9384d5d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n","  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"]},{"name":"stdout","output_type":"stream","text":["============================ Epoch 0 ============================\n","Training: loss 0.008144985840282422\n","Validation: loss 0.00463022875375656\n","============================ Epoch 1 ============================\n","Training: loss 0.004043672948955018\n","Validation: loss 0.00354206330733923\n","============================ Epoch 2 ============================\n","Training: loss 0.003352849525988628\n","Validation: loss 0.0032060814994636483\n","============================ Epoch 3 ============================\n","Training: loss 0.0030024126717534847\n","Validation: loss 0.0028085731648109765\n","============================ Epoch 4 ============================\n","Training: loss 0.0027640594756703466\n","Validation: loss 0.002659822670188513\n","============================ Epoch 5 ============================\n","Training: loss 0.002515872583313351\n","Validation: loss 0.0022458664118971583\n","============================ Epoch 6 ============================\n","Training: loss 0.0022134549893555442\n","Validation: loss 0.0021291230124584767\n","============================ Epoch 7 ============================\n","Training: loss 0.002070724204910895\n","Validation: loss 0.002031022972676691\n","============================ Epoch 8 ============================\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-89fecdc4cd82>\u001b[0m in \u001b[0;36m<cell line: 212>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-89fecdc4cd82>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-89fecdc4cd82>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_codes_indices_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_codes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clamp_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clamp_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/ROB 498 3D Robot Perception/3D-RP-Project/DeepSDF/model/model_sdf.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_connections\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                                 )\n\u001b[1;32m   1556\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                         \u001b[0margs_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0margs_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m                 raise AttributeError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parameter.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_ParameterMeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TensorMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Make `isinstance(t, Parameter)` return True for custom tensor instances that have the _is_param flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         return super().__instancecheck__(instance) or (\n\u001b[1;32m     10\u001b[0m             isinstance(instance, torch.Tensor) and getattr(instance, '_is_param', False))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class Trainer():\n","    def __init__(self, train_cfg):\n","        self.train_cfg = train_cfg\n","\n","    def __call__(self):\n","        # directories\n","        self.timestamp_run = datetime.now().strftime('%d_%m_%H%M%S')   # timestamp to use for logging data\n","        self.runs_dir = os.path.dirname(runs.__file__)               # directory fo all runs\n","        self.run_dir = os.path.join(self.runs_dir, self.timestamp_run)  # directory for this run\n","        if not os.path.exists(self.run_dir):\n","            os.makedirs(self.run_dir)\n","\n","        # Logging\n","        # self.writer = SummaryWriter(log_dir=self.run_dir)\n","        # self.log_path = os.path.join(self.run_dir, 'settings.yaml')\n","        # with open(self.log_path, 'w') as f:\n","        #     yaml.dump(self.train_cfg, f)\n","\n","        # calculate num objects in samples_dictionary, wich is the number of keys\n","        samples_dict_path = os.path.join(os.path.dirname(results.__file__), f'samples_dict_{train_cfg[\"dataset\"]}.npy')\n","        samples_dict = np.load(samples_dict_path, allow_pickle=True).item()\n","\n","        # instantiate model and optimisers\n","        self.model = sdf_model.SDFModel(\n","                self.train_cfg['num_layers'],\n","                self.train_cfg['skip_connections'],\n","                inner_dim=self.train_cfg['inner_dim'],\n","                latent_size=self.train_cfg['latent_size']\n","            ).float().to(device)\n","\n","        # define optimisers\n","        self.optimizer_model = optim.Adam(self.model.parameters(), lr=self.train_cfg['lr_model'], weight_decay=0)\n","\n","        # generate a unique random latent code for each shape\n","        self.latent_codes = utils_deepsdf.generate_latent_codes(self.train_cfg['latent_size'], samples_dict)\n","        self.optimizer_latent = optim.Adam([self.latent_codes], lr=self.train_cfg['lr_latent'], weight_decay=0)\n","\n","        # Load pretrained weights and optimisers to continue training\n","        if self.train_cfg['pretrained']:\n","            # load pretrained weights\n","            self.model.load_state_dict(torch.load(self.train_cfg['pretrain_weights'], map_location=device))\n","\n","            # load pretrained optimisers\n","            self.optimizer_model.load_state_dict(torch.load(self.train_cfg['pretrain_optim_model'], map_location=device))\n","\n","            # retrieve latent codes from results.npy file\n","            results_path = self.train_cfg['pretrain_optim_model'].split(os.sep)\n","            results_path[-1] = 'results.npy'\n","            results_path = os.sep.join(results_path)\n","            # load latent codes from results.npy file\n","            results_latent_codes = np.load(results_path, allow_pickle=True).item()\n","            self.latent_codes = torch.tensor(results_latent_codes['best_latent_codes']).float().to(device)\n","            self.optimizer_latent = optim.Adam([self.latent_codes], lr=self.train_cfg['lr_latent'], weight_decay=0)\n","            self.optimizer_latent.load_state_dict(torch.load(self.train_cfg['pretrain_optim_latent'], map_location=device))\n","\n","        if self.train_cfg['lr_scheduler']:\n","            self.scheduler_model =  torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer_model, mode='min', factor=self.train_cfg['lr_multiplier'], patience=self.train_cfg['patience'], threshold=0.0001, threshold_mode='rel')\n","            self.scheduler_latent =  torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer_latent, mode='min', factor=self.train_cfg['lr_multiplier'], patience=self.train_cfg['patience'], threshold=0.0001, threshold_mode='rel')\n","\n","        # get data\n","        train_loader, val_loader = self.get_loaders()\n","        self.results = {\n","            'best_latent_codes' : []\n","        }\n","\n","        best_loss = 10000000000\n","        start = time.time()\n","        for epoch in range(self.train_cfg['epochs']):\n","            print(f'============================ Epoch {epoch} ============================')\n","            self.epoch = epoch\n","\n","            avg_train_loss = self.train(train_loader)\n","\n","            with torch.no_grad():\n","                avg_val_loss = self.validate(val_loader)\n","\n","                if avg_val_loss < best_loss:\n","                    best_loss = np.copy(avg_val_loss)\n","                    best_weights = self.model.state_dict()\n","                    best_latent_codes = self.latent_codes.detach().cpu().numpy()\n","                    optimizer_model_state = self.optimizer_model.state_dict()\n","                    optimizer_latent_state = self.optimizer_latent.state_dict()\n","\n","                    np.save(os.path.join(self.run_dir, 'results.npy'), self.results)\n","                    torch.save(best_weights, os.path.join(self.run_dir, 'weights.pt'))\n","                    torch.save(optimizer_model_state, os.path.join(self.run_dir, 'optimizer_model_state.pt'))\n","                    torch.save(optimizer_latent_state, os.path.join(self.run_dir, 'optimizer_latent_state.pt'))\n","                    self.results['best_latent_codes'] = best_latent_codes\n","\n","                if self.train_cfg['lr_scheduler']:\n","                    self.scheduler_model.step(avg_val_loss)\n","                    self.scheduler_latent.step(avg_val_loss)\n","\n","                    # self.writer.add_scalar('Learning rate (model)', self.scheduler_model._last_lr[0], epoch)\n","                    # self.writer.add_scalar('Learning rate (latent)', self.scheduler_latent._last_lr[0], epoch)\n","\n","        end = time.time()\n","        print(f'Time elapsed: {end - start} s')\n","\n","    def get_loaders(self):\n","        data = dataset.SDFDataset(self.train_cfg['dataset'])\n","\n","        if self.train_cfg['clamp']:\n","            data.data['sdf'] = torch.clamp(data.data['sdf'], -self.train_cfg['clamp_value'], self.train_cfg['clamp_value'])\n","\n","        train_size = int(0.85 * len(data))\n","        val_size = len(data) - train_size\n","        train_data, val_data = random_split(data, [train_size, val_size])\n","        train_loader = DataLoader(\n","                train_data,\n","                batch_size=self.train_cfg['batch_size'],\n","                shuffle=True,\n","                drop_last=True\n","            )\n","        val_loader = DataLoader(\n","            val_data,\n","            batch_size=self.train_cfg['batch_size'],\n","            shuffle=False,\n","            drop_last=True\n","            )\n","        return train_loader, val_loader\n","\n","    def generate_xy(self, batch):\n","        \"\"\"\n","        Combine latent code and coordinates.\n","        Return:\n","            - x: latent codes + coordinates, torch tensor shape (batch_size, latent_size + 3)\n","            - y: ground truth sdf, shape (batch_size, 1)\n","            - latent_codes_indices_batch: all latent class indices per sample, shape (batch size, 1).\n","                                            e.g. [[2], [2], [1], ..] eaning the batch contains the 2nd, 2nd, 1st latent code\n","            - latent_batch_codes: all latent codes per sample, shape (batch_size, latent_size)\n","        Return ground truth as y, and the latent codes for this batch.\n","        \"\"\"\n","        latent_classes_batch = batch[0][:, 0].view(-1, 1).to(torch.long)               # shape (batch_size, 1)\n","        coords = batch[0][:, 1:]                                  # shape (batch_size, 3)\n","        latent_codes_batch = self.latent_codes[latent_classes_batch.view(-1)]    # shape (batch_size, 128)\n","\n","        x = torch.hstack((latent_codes_batch, coords))                  # shape (batch_size, 131)\n","        y = batch[1]     # (batch_size, 1)\n","\n","        return x, y, latent_classes_batch.view(-1), latent_codes_batch\n","\n","    def train(self, train_loader):\n","        total_loss = 0.0\n","        iterations = 0.0\n","        self.model.train()\n","        for batch in train_loader:\n","            # batch[0]: [class, x, y, z], shape: (batch_size, 4)\n","            # batch[1]: [sdf], shape: (batch size)\n","            iterations += 1.0\n","\n","            self.optimizer_model.zero_grad()\n","            self.optimizer_latent.zero_grad()\n","\n","            x, y, latent_codes_indices_batch, latent_codes_batch = self.generate_xy(batch)\n","\n","            predictions = self.model(x)  # (batch_size, 1)\n","            if self.train_cfg['clamp']:\n","                predictions = torch.clamp(predictions, -self.train_cfg['clamp_value'], self.train_cfg['clamp_value'])\n","\n","            loss_value, loss_rec, loss_latent = self.train_cfg['loss_multiplier'] * SDFLoss_multishape(y, predictions, x[:, :self.train_cfg['latent_size']], sigma=self.train_cfg['sigma_regulariser'])\n","            loss_value.backward()\n","\n","            self.optimizer_latent.step()\n","            self.optimizer_model.step()\n","            total_loss += loss_value.data.cpu().numpy()\n","\n","        avg_train_loss = total_loss/iterations\n","        print(f'Training: loss {avg_train_loss}')\n","        # self.writer.add_scalar('Training loss', avg_train_loss, self.epoch)\n","\n","        return avg_train_loss\n","\n","    def validate(self, val_loader):\n","        total_loss = 0.0\n","        total_loss_rec = 0.0\n","        total_loss_latent = 0.0\n","        iterations = 0.0\n","        self.model.eval()\n","\n","        for batch in val_loader:\n","            # batch[0]: [class, x, y, z], shape: (batch_size, 4)\n","            # batch[1]: [sdf], shape: (batch size)\n","            iterations += 1.0\n","\n","            x, y, _, latent_codes_batch = self.generate_xy(batch)\n","\n","            predictions = self.model(x)  # (batch_size, 1)\n","            if train_cfg['clamp']:\n","                predictions = torch.clamp(predictions, -train_cfg['clamp_value'], train_cfg['clamp_value'])\n","\n","            loss_value, loss_rec, loss_latent = self.train_cfg['loss_multiplier'] * SDFLoss_multishape(y, predictions, latent_codes_batch, self.train_cfg['sigma_regulariser'])\n","            total_loss += loss_value.data.cpu().numpy()\n","            total_loss_rec += loss_rec.data.cpu().numpy()\n","            total_loss_latent += loss_latent.data.cpu().numpy()\n","\n","        avg_val_loss = total_loss/iterations\n","        avg_loss_rec = total_loss_rec/iterations\n","        avg_loss_latent = total_loss_latent/iterations\n","        print(f'Validation: loss {avg_val_loss}')\n","        # self.writer.add_scalar('Validation loss', avg_val_loss, self.epoch)\n","        # self.writer.add_scalar('Reconstruction loss', avg_loss_rec, self.epoch)\n","        # self.writer.add_scalar('Latent code loss', avg_loss_latent, self.epoch)\n","\n","        return avg_val_loss\n","\n","train_cfg_path = os.path.join(os.path.dirname(config_files.__file__), 'train_sdf.yaml')\n","with open(train_cfg_path, 'rb') as f:\n","    train_cfg = yaml.load(f, Loader=yaml.FullLoader)\n","\n","trainer = Trainer(train_cfg)\n","trainer()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
